{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.exceptions import RestException\n",
    "import pandas as pd\n",
    "from utils import common_functions \n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "import keras.models\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import os \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESOURCE_ALREADY_EXISTS: Experiment 'INV_WV_PLUS_MODELS' already exists.\n",
      "Full name INV_WV_PLUS_MODELS\n"
     ]
    }
   ],
   "source": [
    "remote_server_uri = \"http://34.58.215.162:8080/\"  # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "\n",
    "#Creacion o identificacion del experimento \n",
    "try:\n",
    "    experiment_name = 'INV_WV_PLUS_MODELS' #Puede ser cualquiera siempre y cuando no se troque con otro\n",
    "    experiment_id = (mlflow\n",
    "                        .create_experiment(name=experiment_name\n",
    "                                            ,tags={'created_by':'Victor Moreno'})) #importante poner el nombre de quien lo crea\n",
    "except RestException as r:\n",
    "    print(r)\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    print('Full name',experiment.name)\n",
    "    experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(run_id):\n",
    "    loaded_model = f\"runs:/{run_id}/model\"\n",
    "    try:\n",
    "        loaded_model = mlflow.pyfunc.load_model(loaded_model)\n",
    "        model = loaded_model.get_raw_model()\n",
    "    except ValueError as e:\n",
    "        mlflow.artifacts.download_artifacts(artifact_uri=f'runs:/{run_id}/model/data/model.keras',dst_path='.')\n",
    "        model = keras.models.load_model('model.keras',custom_objects={'LeakyReLU':LeakyReLU})\n",
    "        os.remove('model.keras')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/datos_PEPEUSDT.csv',header=0)\n",
    "\n",
    "#multipling by 1M the close data\n",
    "df['closex1M'] = df['Close']*1000000 #PEPE\n",
    "#df['closex1M'] = df['Close']*100 #DOGE\n",
    "\n",
    "select = ['Close time_date','closex1M']\n",
    "df_clean = df[select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wt_coeff_inv = common_functions().get_wt_coeff_inv\n",
    "plot_inv_wv = common_functions().plot_inv_wv\n",
    "create_sequences = common_functions().create_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df_clean.shape[0] #Cantidad de puntos a tratar\n",
    "data = np.array(df_clean['closex1M'][:n]) #valores de la serie temporal\n",
    "dates = df_clean['Close time_date'][:n] #valores de las fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inv_coeff(wavelet):\n",
    "    #llamando la funcion de get_wt_coeff_inv para obtener \n",
    "    ## Coeficientes de wavelet y la senal resconstruida desde estos\n",
    "    coeffs_lv3, inv_coeffs_lv3 = get_wt_coeff_inv(signal=data\n",
    "                                        ,wavelet=wavelet\n",
    "                                        ,level=3\n",
    "                                        ,mode='symmetric'\n",
    "                                        ,take=n)\n",
    "\n",
    "    coeffs_lv1, inv_coeffs_lv1 = get_wt_coeff_inv(signal=data\n",
    "                                        ,wavelet=wavelet#'db1'\n",
    "                                        ,level=1\n",
    "                                        ,mode='symmetric'\n",
    "                                        ,take=n)\n",
    "\n",
    "\n",
    "    coeffs_lv2, inv_coeffs_lv2 = get_wt_coeff_inv(signal=data\n",
    "                                        ,wavelet=wavelet\n",
    "                                        ,level=2\n",
    "                                        ,mode='symmetric'\n",
    "                                        ,take=n)\n",
    "\n",
    "    coeffs_lv4, inv_coeffs_lv4 = get_wt_coeff_inv(signal=data\n",
    "                                        ,wavelet=wavelet\n",
    "                                        ,level=4\n",
    "                                        ,mode='symmetric'\n",
    "                                        ,take=n)\n",
    "    output = {'coeffs_lv1':coeffs_lv1,\n",
    "              'inv_coeffs_lv1':inv_coeffs_lv1,\n",
    "              'coeffs_lv2':coeffs_lv2,\n",
    "              'inv_coeffs_lv2':inv_coeffs_lv2,\n",
    "              'coeffs_lv3':coeffs_lv3,\n",
    "              'inv_coeffs_lv3':inv_coeffs_lv3,\n",
    "              'coeffs_lv4':coeffs_lv4,\n",
    "              'inv_coeffs_lv4':inv_coeffs_lv4}\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_traina, y_vala = train_test_split(df_clean,test_size=0.3,shuffle=False)\n",
    "y_vala, y_testa = train_test_split(y_vala,test_size=0.1,shuffle=False)\n",
    "y_testa = y_testa['closex1M'].values\n",
    "y_testa = y_testa[:-1]\n",
    "y_testa.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATING THE MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_runid = '032cc4d2e33241fcbe739bcd55ea97df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runs = mlflow.search_runs(experiment_ids=experiment_id)\n",
    "df_runs = df_runs[df_runs['tags.mlflow.parentRunId']==parent_runid]\n",
    "for run_id in df_runs['run_id'].values:\n",
    "    df_run = df_runs[df_runs['run_id']==run_id].head()\n",
    "    wavelet = df_run['params.wavelet'].values[0]\n",
    "    wavelet = wavelet if wavelet!= None else 'db1'\n",
    "    aproximacion = df_run['params.CoeficienteAproximacion'].values[0]\n",
    "    detalle = df_run['params.CoeficienteDetalle'].values[0]\n",
    "    print(run_id)\n",
    "\n",
    "    #cargando modelo \n",
    "    model = load_model(run_id)\n",
    "    inv_coeffs= load_inv_coeff(wavelet)\n",
    "\n",
    "    print(f'inv_coeffs_lv{aproximacion[-1]}',f'inv_coeffs_lv{detalle[-1]}')\n",
    "    df_train = pd.DataFrame({aproximacion:inv_coeffs[f'inv_coeffs_lv{aproximacion[-1]}'][aproximacion]\n",
    "                             ,detalle:inv_coeffs[f'inv_coeffs_lv{detalle[-1]}'][detalle]})\n",
    "    \n",
    "    window_size = 24\n",
    "    \n",
    "    X, Y = create_sequences(df_train,window_size=window_size,target_col=aproximacion)\n",
    "\n",
    "    #Espliteando la data\n",
    "    X_train, X_vt, y_train, y_vt = train_test_split(X, Y, test_size=0.3, shuffle=False)\n",
    "\n",
    "    x_val, x_test, y_val, y_test = train_test_split(X_vt,y_vt,test_size=0.1, shuffle=False)\n",
    "\n",
    "    #Obteniendo las prediccciones del modelo\n",
    "    train_pred = model.predict(X_train).reshape(-1)\n",
    "    val_pred = model.predict(x_val).reshape(-1)\n",
    "    test_pred = model.predict(x_test).reshape(-1)\n",
    "\n",
    "    rmse_test = root_mean_squared_error(y_true=y_test,y_pred=test_pred)\n",
    "    rmse_train = root_mean_squared_error(y_true=y_train, y_pred=train_pred)\n",
    "    rmse_val = root_mean_squared_error(y_true=y_val, y_pred=val_pred)\n",
    "\n",
    "    print(f\"RMSE train: {rmse_train},   RMSE val: {rmse_val},  RMSE test: {rmse_test}\\n\")\n",
    "\n",
    "    metrics = {'rmse_train':rmse_train,'rmse_val':rmse_val,'rmse_test':rmse_test}\n",
    "    del model\n",
    "    del train_pred, val_pred, test_pred\n",
    "\n",
    "\n",
    "    #for metric,value in metrics.items():\n",
    "    #    mlflow.log_metric(metric,value,run_id=run_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_runid = '6d1b256d8a7144a89146e017c0a7a178'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e28ef98ca1834900b39a1a78558259ed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victormoreno/Desktop/master/TFE/Develop/tfm_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:01<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_coeffs_lv1 inv_coeffs_lv3\n",
      "RMSE train: 1.649180610032769,  RMSE test: 9.535860132898161\n",
      "\n",
      "76bf3b9f925c463cb52d7236beb184c9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:01<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_coeffs_lv1 inv_coeffs_lv3\n",
      "RMSE train: 1.649180610032769,  RMSE test: 9.535860132898161\n",
      "\n",
      "d22bc88b9bf746898e6f88c8f26a24ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:01<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_coeffs_lv1 inv_coeffs_lv3\n",
      "RMSE train: 1.649180610032769,  RMSE test: 9.535860132898161\n",
      "\n",
      "6f58ca16606d4ac4b1e0183473a834a0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:01<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_coeffs_lv1 inv_coeffs_lv3\n",
      "RMSE train: 1.6490008995666414,  RMSE test: 9.5490083988102\n",
      "\n",
      "eafac46063924b5b92899ea7b1569bfd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:02<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_coeffs_lv3 inv_coeffs_lv1\n",
      "RMSE train: 1.6500173285183268,  RMSE test: 9.541440123521033\n",
      "\n",
      "6e6af7b9640c4de8b645277b8e3bcb27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:01<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_coeffs_lv3 inv_coeffs_lv1\n",
      "RMSE train: 1.6793379999764486,  RMSE test: 9.534569554732546\n",
      "\n",
      "e4333e7e699948e7a66b8e86595e75f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:01<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_coeffs_lv3 inv_coeffs_lv1\n",
      "RMSE train: 1.6793379999764486,  RMSE test: 9.534569554732546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_runs = mlflow.search_runs(experiment_ids=experiment_id)\n",
    "df_runs = df_runs[df_runs['tags.mlflow.parentRunId']==parent_runid]\n",
    "for run_id in df_runs['run_id'].values:\n",
    "    df_run = df_runs[df_runs['run_id']==run_id].head()\n",
    "    wavelet = df_run['params.wavelet'].values[0]\n",
    "    wavelet = wavelet if wavelet!= None else 'db1'\n",
    "    aproximacion = df_run['params.CoeficienteAproximacion'].values[0]\n",
    "    detalle = df_run['params.CoeficienteDetalle'].values[0]\n",
    "    print(run_id)\n",
    "\n",
    "    #cargando modelo \n",
    "    model = load_model(run_id)\n",
    "    inv_coeffs= load_inv_coeff(wavelet)\n",
    "\n",
    "    print(f'inv_coeffs_lv{aproximacion[-1]}',f'inv_coeffs_lv{detalle[-1]}')\n",
    "    df_train = pd.DataFrame({'ds':df_clean['Close time_date']\n",
    "                            ,'y':inv_coeffs[f'inv_coeffs_lv{aproximacion[-1]}'][aproximacion]\n",
    "                             ,detalle:inv_coeffs[f'inv_coeffs_lv{detalle[-1]}'][detalle]})\n",
    "\n",
    "    def split_data(df,partitions,method='points'):\n",
    "        df_ = df.copy()\n",
    "        if method == 'percent':\n",
    "            num_points = df_.shape[0]\n",
    "            up_limit_train = math.ceil(num_points*partitions[0])\n",
    "            #up_limit_test = math.ceil(up_limit_train + num_points*partitions[1])\n",
    "        else:\n",
    "            up_limit_train = partitions[0]\n",
    "\n",
    "        df_train = df_.iloc[:up_limit_train]\n",
    "        df_test = df_.iloc[up_limit_train:]\n",
    "\n",
    "        return df_train,df_test\n",
    "\n",
    "    df_train,df_test = split_data(df_train,[14861,None],'points') \n",
    "    y_test = df_clean['closex1M'].iloc[df_train.shape[0]:]\n",
    "    y_train = df_clean['closex1M'].iloc[:df_train.shape[0]]\n",
    "    \n",
    "\n",
    "    train_pred_df = model.predict(df_train)\n",
    "    test_pred_df = model.predict(df_test)\n",
    "    train_pred = train_pred_df['yhat']\n",
    "    test_pred = test_pred_df['yhat']\n",
    "\n",
    "    rmse_test = root_mean_squared_error(y_true=y_test,y_pred=test_pred)\n",
    "    rmse_train = root_mean_squared_error(y_true=y_train, y_pred=train_pred)\n",
    "\n",
    "    print(f\"RMSE train: {rmse_train},  RMSE test: {rmse_test}\\n\")\n",
    "\n",
    "    metrics = {'rmse_train':rmse_train,'rmse_test':rmse_test}\n",
    "    del model\n",
    "    del train_pred, test_pred\n",
    "\n",
    "\n",
    "    for metric,value in metrics.items():\n",
    "        mlflow.log_metric(metric,value,run_id=run_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDING THE REAL MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Close time_date', 'closex1M'], dtype='object'),\n",
       " Index(['cA3', 'cD1'], dtype='object'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_runid = '032cc4d2e33241fcbe739bcd55ea97df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00d56ebd83334d37b2818c233e04d1a4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 6/6 [00:00<00:00,  6.91it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_coeffs_lv3 inv_coeffs_lv1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cA3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/master/TFE/Develop/tfm_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cA3'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m df_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({aproximacion:inv_coeffs[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minv_coeffs_lv\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maproximacion[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][aproximacion]\n\u001b[1;32m     17\u001b[0m                          ,detalle:inv_coeffs[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minv_coeffs_lv\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetalle[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][detalle]})\n\u001b[1;32m     19\u001b[0m window_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24\u001b[39m\n\u001b[0;32m---> 21\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maproximacion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#Espliteando la data\u001b[39;00m\n\u001b[1;32m     24\u001b[0m X_train, X_vt, y_train, y_vt \u001b[38;5;241m=\u001b[39m train_test_split(X, Y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/master/TFE/Develop/TFM_crypto/INV_WV_PLUS_MODELS/utils.py:51\u001b[0m, in \u001b[0;36mcommon_functions.create_sequences\u001b[0;34m(self, data, window_size, target_col)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m-\u001b[39m window_size):\n\u001b[1;32m     50\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(data\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mwindow_size])  \u001b[38;5;66;03m# Ventana de entrada\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     y\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m]\u001b[49m[i\u001b[38;5;241m+\u001b[39mwindow_size])    \u001b[38;5;66;03m# Valor a predecir\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(X), np\u001b[38;5;241m.\u001b[39marray(y)\n",
      "File \u001b[0;32m~/Desktop/master/TFE/Develop/tfm_env/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/master/TFE/Develop/tfm_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cA3'"
     ]
    }
   ],
   "source": [
    "df_runs = mlflow.search_runs(experiment_ids=experiment_id)\n",
    "df_runs = df_runs[df_runs['tags.mlflow.parentRunId']==parent_runid]\n",
    "for run_id in df_runs['run_id'].values:\n",
    "    df_run = df_runs[df_runs['run_id']==run_id].head()\n",
    "    wavelet = df_run['params.wavelet'].values[0]\n",
    "    wavelet = wavelet if wavelet!= None else 'db1'\n",
    "    aproximacion = df_run['params.CoeficienteAproximacion'].values[0]\n",
    "    detalle = df_run['params.CoeficienteDetalle'].values[0]\n",
    "    print(run_id)\n",
    "\n",
    "    #cargando modelo \n",
    "    model = load_model(run_id)\n",
    "    inv_coeffs= load_inv_coeff(wavelet)\n",
    "\n",
    "    print(f'inv_coeffs_lv{aproximacion[-1]}',f'inv_coeffs_lv{detalle[-1]}')\n",
    "    df_train = pd.DataFrame({aproximacion:inv_coeffs[f'inv_coeffs_lv{aproximacion[-1]}'][aproximacion]\n",
    "                             ,detalle:inv_coeffs[f'inv_coeffs_lv{detalle[-1]}'][detalle]})\n",
    "    \n",
    "    window_size = 24\n",
    "    \n",
    "    X, Y = create_sequences(df_clean,window_size=window_size,target_col=aproximacion)\n",
    "\n",
    "    #Espliteando la data\n",
    "    X_train, X_vt, y_train, y_vt = train_test_split(X, Y, test_size=0.3, shuffle=False)\n",
    "\n",
    "    x_val, x_test, y_val, y_test = train_test_split(X_vt,y_vt,test_size=0.1, shuffle=False)\n",
    "\n",
    "    y_train_r = df_clean.iloc[:len(y_train)]\n",
    "    y_val_r = df_clean.iloc[len(y_train):len(y_train)+len(y_val)]\n",
    "    y_test_r = df_clean.iloc[len(y_train)+len(y_val):]\n",
    "\n",
    "    print(f\"y_train: {len(y_train)} ---- y_train_r: {len(y_train_r)}\")\n",
    "    print(f\"y_val: {len(y_val)} ---- y_val_r: {len(y_val_r)}\")\n",
    "    print(f\"y_test: {len(y_test)} ---- y_test_r: {len(y_test_r)}\")\n",
    "\n",
    "    #Obteniendo las prediccciones del modelo\n",
    "    train_pred = model.predict(X_train).reshape(-1)\n",
    "    val_pred = model.predict(x_val).reshape(-1)\n",
    "    test_pred = model.predict(x_test).reshape(-1)\n",
    "\n",
    "    rmse_test = root_mean_squared_error(y_true=y_test,y_pred=test_pred)\n",
    "    rmse_train = root_mean_squared_error(y_true=y_train, y_pred=train_pred)\n",
    "    rmse_val = root_mean_squared_error(y_true=y_val, y_pred=val_pred)\n",
    "\n",
    "    print(f\"RMSE_real train: {rmse_train},   RMSE_real val: {rmse_val},  RMSE_real test: {rmse_test}\\n\")\n",
    "\n",
    "    metrics = {'real_rmse_train':rmse_train,'real_rmse_val':rmse_val,'real_rmse_test':rmse_test}\n",
    "    del model\n",
    "    del train_pred, val_pred, test_pred\n",
    "\n",
    "\n",
    "    #for metric,value in metrics.items():\n",
    "    #    mlflow.log_metric(metric,value,run_id=run_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm_jupyter_kernel",
   "language": "python",
   "name": "tfm_env_jp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
